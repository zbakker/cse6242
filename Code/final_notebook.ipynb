{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all Libraries and set path varaibles \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from restaurant_index import restaurant_index\n",
    "from crime_index import crime_index\n",
    "from transit_index import transit_index\n",
    "from housing_index import housing_index\n",
    "from health_index import health_index\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "#USER SET VARIABLES \n",
    "path=\"team104final/Data/\"\n",
    "test_files=\"Test_files/\"\n",
    "RAW_RUN=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW RUN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This section will run with RAW data and calulate each individual index. \n",
    "\n",
    "if RAW_RUN==True:\n",
    "    restaurant_index_df=restaurant_index(path+\"DOHMH_New_York_City_Restaurant_Inspection_Results_20231025.csv\")\n",
    "    restaurant_index_df.to_csv(test_files+'restaurant_index_df.csv',index=False)\n",
    "\n",
    "    crime_index_df=crime_index(path+\"Crime_Map_.csv\")\n",
    "    crime_index_df.to_csv(test_files+'crime_index_df.csv',index=False)\n",
    "\n",
    "    transit_index_df=transit_index(subway_data=path+'MTA_NYCT_Subway_Entrances_and_Exits__2015_20231113.csv', bus_data=path+'Bus_Stop_Shelter.csv', bike_data=path+'BicycleParking.csv')\n",
    "    transit_index_df.to_csv(test_files+'transit_index_df.csv')\n",
    "\n",
    "    health_index_df=health_index(water_inspection_data=path+\"Water_inspection_data.csv\",Rodent_Inspection_data=path+\"Rodent_Inspection_data.csv\",Influenza_Pneumonia_data=path+\"Influenza_Pneumonia_data.csv\",EMS_Incident_data=path+\"EMS_Incident_data.csv\")\n",
    "    health_index_df.to_csv(test_files+\"health_index_df.csv\",index=False)\n",
    "\n",
    "\n",
    "    housing_index_df=housing_index(projects_data=path+'projects_data.csv', buildings_data=path+\"buildings_data.csv\", rent_data=path+'rent_data.csv', violations_data=path+\"violations_data.csv\")\n",
    "    housing_index_df.to_csv(test_files+\"housing_index_df.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## TRANSIT WITH CENSUS_GEOID\n",
    "\n",
    "    # transit_index_df=transit_index(subway_data=\"Test_files/subway_entrances.csv\", bus_data=\"Test_files/bus_stops.csv\", bike_data=\"Test_files/bike_parking.csv\")\n",
    "    ############\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processed Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This will run using the pre-processed data saved inside \"test_files\"\n",
    "\n",
    "restaurant_index_df=pd.read_csv(test_files+'restaurant_index_df.csv')\n",
    "restaurant_index_df['restaurant_index']=restaurant_index_df['linear_equation']\n",
    "restaurant_index_df=restaurant_index_df[['census_tract_geoid','restaurant_index']]\n",
    "\n",
    "\n",
    "crime_index_df=pd.read_csv(test_files+\"crime_index_df.csv\")\n",
    "crime_index_df['crime_index']=crime_index_df['StandardizedScore']\n",
    "crime_index_df=crime_index_df[['census_tract_geoid','crime_index']]\n",
    "\n",
    "transit_index_df=pd.read_csv(test_files+\"transit_index_df.csv\")\n",
    "transit_index_df['transit_index']=transit_index_df['index_score']\n",
    "transit_index_df=transit_index_df[['census_tract_geoid','transit_index']]\n",
    "\n",
    "health_index_df=pd.read_csv(test_files+\"health_index_df.csv\")\n",
    "health_index_df[['health_index']]=health_index_df[['Health_Index']]\n",
    "health_index_df=health_index_df[['census_tract_geoid','health_index']]\n",
    "\n",
    "housing_index_df=pd.read_csv(test_files+\"housing_index_df.csv\")\n",
    "housing_index_df[['housing_index']]=housing_index_df[['index_score']]\n",
    "housing_index_df=housing_index_df[['census_tract_geoid','housing_index']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "census_tract_geoid       0\n",
       "restaurant_index       360\n",
       "crime_index              2\n",
       "transit_index          302\n",
       "health_index          2031\n",
       "housing_index           73\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This joins all indexes together\n",
    "join1=restaurant_index_df.merge(crime_index_df,on=\"census_tract_geoid\",how='outer')\n",
    "join2=join1.merge(transit_index_df,on='census_tract_geoid',how='outer')\n",
    "join3=join2.merge(health_index_df,on='census_tract_geoid',how='outer')\n",
    "join4=join3.merge(housing_index_df,on='census_tract_geoid',how='outer')\n",
    "\n",
    "join4.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "census_tract_geoid       0\n",
       "restaurant_index       190\n",
       "crime_index              0\n",
       "transit_index          142\n",
       "health_index          1852\n",
       "housing_index           20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This removes rows with >3 missing indexes \n",
    "row_keep=[]\n",
    "for i in range(len(join4)):\n",
    "    if join4.iloc[i].isna().sum()<3:\n",
    "        row_keep.append(i)\n",
    "rows_underThree_na=join4.iloc[row_keep]\n",
    "rows_underThree_na.isnull().sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This imputes missing data for missing indexes and outputs to csv\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "final_noNa=rows_underThree_na.copy()\n",
    "missing_data=['restaurant_index','health_index','transit_index','crime_index','housing_index']\n",
    "final_noNa[missing_data] = imp.fit_transform(final_noNa[missing_data])\n",
    "final_index=final_noNa.copy()\n",
    "final_index.to_csv(test_files+'Final/final_index.csv',index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
