{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'restaurant_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jared\\Downloads\\final_notebook.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrestaurant_index\u001b[39;00m \u001b[39mimport\u001b[39;00m restaurant_index\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcrime_index\u001b[39;00m \u001b[39mimport\u001b[39;00m crime_index\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransit_index\u001b[39;00m \u001b[39mimport\u001b[39;00m transit_index\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'restaurant_index'"
     ]
    }
   ],
   "source": [
    "# Import all Libraries and set path varaibles \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from restaurant_index import restaurant_index\n",
    "from crime_index import crime_index\n",
    "from transit_index import transit_index\n",
    "from housing_index import housing_index\n",
    "from health_index import health_index\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "#USER SET VARIABLES \n",
    "path=\"team104final/Data/\"\n",
    "test_files=\"Test_files/\"\n",
    "RAW_RUN=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW RUN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This section will run with RAW data and calulate each individual index. \n",
    "\n",
    "if RAW_RUN==True:\n",
    "    restaurant_index_df=restaurant_index(path+\"DOHMH_New_York_City_Restaurant_Inspection_Results_20231025.csv\")\n",
    "    restaurant_index_df.to_csv(test_files+'restaurant_index_df.csv',index=False)\n",
    "\n",
    "    crime_index_df=crime_index(path+\"Crime_Map_.csv\")\n",
    "    crime_index_df.to_csv(test_files+'crime_index_df.csv',index=False)\n",
    "\n",
    "    transit_index_df=transit_index(subway_data=path+'MTA_NYCT_Subway_Entrances_and_Exits__2015_20231113.csv', bus_data=path+'Bus_Stop_Shelter.csv', bike_data=path+'BicycleParking.csv')\n",
    "    transit_index_df.to_csv(test_files+'transit_index_df.csv')\n",
    "\n",
    "    health_index_df=health_index(water_inspection_data=path+\"Water_inspection_data.csv\",Rodent_Inspection_data=path+\"Rodent_Inspection_data.csv\",Influenza_Pneumonia_data=path+\"Influenza_Pneumonia_data.csv\",EMS_Incident_data=path+\"EMS_Incident_data.csv\")\n",
    "    health_index_df.to_csv(test_files+\"health_index_df.csv\",index=False)\n",
    "\n",
    "\n",
    "    housing_index_df=housing_index(projects_data=path+'projects_data.csv', buildings_data=path+\"buildings_data.csv\", rent_data=path+'rent_data.csv', violations_data=path+\"violations_data.csv\")\n",
    "    housing_index_df.to_csv(test_files+\"housing_index_df.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## TRANSIT WITH CENSUS_GEOID\n",
    "\n",
    "    # transit_index_df=transit_index(subway_data=\"Test_files/subway_entrances.csv\", bus_data=\"Test_files/bus_stops.csv\", bike_data=\"Test_files/bike_parking.csv\")\n",
    "    ############\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processed Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This will run using the pre-processed data saved inside \"test_files\"\n",
    "\n",
    "restaurant_index_df=pd.read_csv(test_files+'restaurant_index_df.csv')\n",
    "restaurant_index_df['restaurant_index']=restaurant_index_df['linear_equation']\n",
    "restaurant_index_df=restaurant_index_df[['census_tract_geoid','restaurant_index']]\n",
    "\n",
    "\n",
    "crime_index_df=pd.read_csv(test_files+\"crime_index_df.csv\")\n",
    "crime_index_df['crime_index']=crime_index_df['StandardizedScore']\n",
    "crime_index_df=crime_index_df[['census_tract_geoid','crime_index']]\n",
    "\n",
    "transit_index_df=pd.read_csv(test_files+\"transit_index_df.csv\")\n",
    "transit_index_df['transit_index']=transit_index_df['index_score']\n",
    "transit_index_df=transit_index_df[['census_tract_geoid','transit_index']]\n",
    "\n",
    "health_index_df=pd.read_csv(test_files+\"health_index_df.csv\")\n",
    "health_index_df[['health_index']]=health_index_df[['Health_Index']]\n",
    "health_index_df=health_index_df[['census_tract_geoid','health_index']]\n",
    "\n",
    "housing_index_df=pd.read_csv(test_files+\"housing_index_df.csv\")\n",
    "housing_index_df[['housing_index']]=housing_index_df[['index_score']]\n",
    "housing_index_df=housing_index_df[['census_tract_geoid','housing_index']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "census_tract_geoid       0\n",
       "restaurant_index       360\n",
       "crime_index              2\n",
       "transit_index          302\n",
       "health_index          2031\n",
       "housing_index           73\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This joins all indexes together\n",
    "join1=restaurant_index_df.merge(crime_index_df,on=\"census_tract_geoid\",how='outer')\n",
    "join2=join1.merge(transit_index_df,on='census_tract_geoid',how='outer')\n",
    "join3=join2.merge(health_index_df,on='census_tract_geoid',how='outer')\n",
    "join4=join3.merge(housing_index_df,on='census_tract_geoid',how='outer')\n",
    "\n",
    "join4.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "census_tract_geoid       0\n",
       "restaurant_index       190\n",
       "crime_index              0\n",
       "transit_index          142\n",
       "health_index          1852\n",
       "housing_index           20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This removes rows with >3 missing indexes \n",
    "row_keep=[]\n",
    "for i in range(len(join4)):\n",
    "    if join4.iloc[i].isna().sum()<3:\n",
    "        row_keep.append(i)\n",
    "rows_underThree_na=join4.iloc[row_keep]\n",
    "rows_underThree_na.isnull().sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IterativeImputer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jared\\Downloads\\final_notebook.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#This imputes missing data for missing indexes and outputs to csv\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m imp \u001b[39m=\u001b[39m IterativeImputer(max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m final_noNa\u001b[39m=\u001b[39mrows_underThree_na\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jared/Downloads/final_notebook.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m missing_data\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mrestaurant_index\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mhealth_index\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtransit_index\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcrime_index\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mhousing_index\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IterativeImputer' is not defined"
     ]
    }
   ],
   "source": [
    "#This imputes missing data for missing indexes and outputs to csv\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "final_noNa=rows_underThree_na.copy()\n",
    "missing_data=['restaurant_index','health_index','transit_index','crime_index','housing_index']\n",
    "final_noNa[missing_data] = imp.fit_transform(final_noNa[missing_data])\n",
    "final_index=final_noNa.copy()\n",
    "final_index.loc[final_index[\"restaurant_index\"] < 0, \"restaurant_index\"] = 0\n",
    "final_index.loc[final_index[\"health_index\"] < 0, \"health_index\"] = 0\n",
    "final_index.loc[final_index[\"transit_index\"] < 0, \"transit_index\"] = 0\n",
    "final_index.loc[final_index[\"crime_index\"] < 0, \"crime_index\"] = 0\n",
    "final_index.loc[final_index[\"housing_index\"] < 0, \"housing_index\"] = 0\n",
    "\n",
    "# for index, row in final_index.iterrows():\n",
    "#     additon=row['resturant_count_x']+row['resturant_count_y']\n",
    "#     resturant_sum.append(additon)\n",
    "#     violation_ratio=row['sum_violation_count']/(row['resturant_count_x']+row['resturant_count_y'])\n",
    "#     violation_ratio_list.append(violation_ratio)\n",
    "# resturant_count_join_fill['resturant_total']=resturant_sum\n",
    "\n",
    "\n",
    "final_index.to_csv(test_files+'Final/final_index.csv',index=False)\n",
    "\n",
    "final_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULL evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jared\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:800: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0032273613520654833\n"
     ]
    }
   ],
   "source": [
    "null_evaluation_run=True\n",
    "\n",
    "if null_evaluation_run==True:  \n",
    "\n",
    "    #Runs 10 times \n",
    "    mse_loop_list=[]\n",
    "    mse_loop=0\n",
    "    while mse_loop<10:\n",
    "        restaurant_null_perc=190/2147\n",
    "        transit_null_perc=142/2147\n",
    "        health_null_perc=1852/2147\n",
    "        housing_null_perc=20/2147\n",
    "        # Inital split on full index for __ %\n",
    "        final_index_missing=final_index.sample(frac = 1).reset_index()\n",
    "\n",
    "        # Add missing values to restaurant\n",
    "        restaurant_missing_eval=final_index_missing.sample(frac = restaurant_null_perc)\n",
    "        missing_restaurant=[]\n",
    "        for i in restaurant_missing_eval.index:\n",
    "            missing_restaurant.append(i)\n",
    "        for k in final_index_missing.index:\n",
    "            if k in missing_restaurant:\n",
    "                final_index_missing.loc[k,'restaurant_index_missing']=np.NaN\n",
    "            else: \n",
    "                final_index_missing.loc[k,'restaurant_index_missing']=final_index_missing.loc[k,'restaurant_index']\n",
    "\n",
    "        # Add missing values to transit\n",
    "        transit_missing_eval=final_index_missing.sample(frac = transit_null_perc)\n",
    "        missing_transit=[]\n",
    "        for i in transit_missing_eval.index:\n",
    "            missing_transit.append(i)\n",
    "        for k in final_index_missing.index:\n",
    "            if k in missing_transit:\n",
    "                final_index_missing.loc[k,'transit_index_missing']=np.NaN\n",
    "            else: \n",
    "                final_index_missing.loc[k,'transit_index_missing']=final_index_missing.loc[k,'transit_index']\n",
    "\n",
    "\n",
    "        # Add missing values to health\n",
    "        health_missing_eval=final_index_missing.sample(frac = health_null_perc)\n",
    "        missing_health=[]\n",
    "        for i in health_missing_eval.index:\n",
    "            missing_health.append(i)\n",
    "        for k in final_index_missing.index:\n",
    "            if k in missing_health:\n",
    "                final_index_missing.loc[k,'health_index_missing']=np.NaN\n",
    "            else: \n",
    "                final_index_missing.loc[k,'health_index_missing']=final_index_missing.loc[k,'health_index']\n",
    "\n",
    "\n",
    "        # Add missing values to housing\n",
    "        housing_missing_eval=final_index_missing.sample(frac = housing_null_perc)\n",
    "        missing_housing=[]\n",
    "        for i in housing_missing_eval.index:\n",
    "            missing_housing.append(i)\n",
    "        for k in final_index_missing.index:\n",
    "            if k in missing_housing:\n",
    "                final_index_missing.loc[k,'housing_index_missing']=np.NaN\n",
    "            else: \n",
    "                final_index_missing.loc[k,'housing_index_missing']=final_index_missing.loc[k,'housing_index']\n",
    "        \n",
    "        # GRAB ONLY NULL ROWS\n",
    "        null_rows = final_index_missing[final_index_missing.isnull().any(axis=1)]\n",
    "        max_rows=len(null_rows)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Using IterativeImputer fill in missing data that was just randomly generated\n",
    "        imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "        missing_data_eval=['restaurant_index_missing','health_index_missing','transit_index_missing','housing_index_missing']\n",
    "        final_index_missing[missing_data_eval] = imp.fit_transform(final_index_missing[missing_data_eval])\n",
    "\n",
    "        # CALC MSE \n",
    "        final_index_missing['restaurant_mse']=(final_index_missing['restaurant_index_missing']-final_index_missing['restaurant_index'])**2\n",
    "        final_index_missing['transit_mse']=(final_index_missing['transit_index_missing']-final_index_missing['transit_index'])**2\n",
    "        final_index_missing['health_mse']=(final_index_missing['health_index_missing']-final_index_missing['health_index'])**2\n",
    "        final_index_missing['housing_mse']=(final_index_missing['housing_index_missing']-final_index_missing['housing_index'])**2\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        mse=(sum(final_index_missing['restaurant_mse'])+sum(final_index_missing['transit_mse'])+sum(final_index_missing['health_mse'])+sum(final_index_missing['housing_mse']))/max_rows\n",
    "        mse_loop_list.append(mse)\n",
    "        mse_loop+=1\n",
    "    mse_average=np.average(mse_loop_list)\n",
    "    print(\"MSE: \"+str(mse_average))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
