{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all Libraries and set path varaibles \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from restaurant_index import restaurant_index\n",
    "from crime_index import crime_index\n",
    "from transit_index import transit_index\n",
    "from housing_index import housing_index\n",
    "from health_index import health_index\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#USER SET VARIABLES \n",
    "path=\"team104final/Data/\"\n",
    "test_files=\"Test_files/\"\n",
    "RAW_RUN=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAW RUN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This section will run with RAW data and calulate each individual index. \n",
    "\n",
    "if RAW_RUN==True:\n",
    "    restaurant_index_df=restaurant_index(path+\"DOHMH_New_York_City_Restaurant_Inspection_Results_20231025.csv\")\n",
    "    restaurant_index_df.to_csv(test_files+'restaurant_index_df.csv',index=False)\n",
    "\n",
    "    crime_index_df=crime_index(path+\"Crime_Map_.csv\")\n",
    "    crime_index_df.to_csv(test_files+'crime_index_df.csv',index=False)\n",
    "\n",
    "    transit_index_df=transit_index(subway_data=path+'MTA_NYCT_Subway_Entrances_and_Exits__2015_20231113.csv', bus_data=path+'Bus_Stop_Shelter.csv', bike_data=path+'BicycleParking.csv')\n",
    "    transit_index_df.to_csv(test_files+'transit_index_df.csv')\n",
    "\n",
    "    health_index_df=health_index(water_inspection_data=path+\"Water_inspection_data.csv\",Rodent_Inspection_data=path+\"Rodent_Inspection_data.csv\",Influenza_Pneumonia_data=path+\"Influenza_Pneumonia_data.csv\",EMS_Incident_data=path+\"EMS_Incident_data.csv\")\n",
    "    health_index_df.to_csv(test_files+\"health_index_df.csv\",index=False)\n",
    "\n",
    "\n",
    "    housing_index_df=housing_index(projects_data=path+'projects_data.csv', buildings_data=path+\"buildings_data.csv\", rent_data=path+'rent_data.csv', violations_data=path+\"violations_data.csv\")\n",
    "    housing_index_df.to_csv(test_files+\"housing_index_df.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## TRANSIT WITH CENSUS_GEOID\n",
    "\n",
    "    # transit_index_df=transit_index(subway_data=\"Test_files/subway_entrances.csv\", bus_data=\"Test_files/bus_stops.csv\", bike_data=\"Test_files/bike_parking.csv\")\n",
    "    ############\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processed Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This will run using the pre-processed data saved inside \"test_files\"\n",
    "\n",
    "restaurant_index_df=pd.read_csv(test_files+'restaurant_index_df.csv')\n",
    "restaurant_index_df['restaurant_index']=restaurant_index_df['linear_equation']\n",
    "restaurant_index_df=restaurant_index_df[['census_tract_geoid','restaurant_index']]\n",
    "\n",
    "\n",
    "crime_index_df=pd.read_csv(test_files+\"crime_index_df.csv\")\n",
    "crime_index_df['crime_index']=crime_index_df['StandardizedScore']\n",
    "crime_index_df=crime_index_df[['census_tract_geoid','crime_index']]\n",
    "\n",
    "transit_index_df=pd.read_csv(test_files+\"transit_index_df.csv\")\n",
    "transit_index_df['transit_index']=transit_index_df['index_score']\n",
    "transit_index_df=transit_index_df[['census_tract_geoid','transit_index']]\n",
    "\n",
    "health_index_df=pd.read_csv(test_files+\"health_index_df.csv\")\n",
    "health_index_df[['health_index']]=health_index_df[['Health_Index']]\n",
    "health_index_df=health_index_df[['census_tract_geoid','health_index']]\n",
    "\n",
    "housing_index_df=pd.read_csv(test_files+\"housing_index_df.csv\")\n",
    "housing_index_df[['housing_index']]=housing_index_df[['index_score']]\n",
    "housing_index_df=housing_index_df[['census_tract_geoid','housing_index']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "census_tract_geoid       0\n",
       "restaurant_index       360\n",
       "crime_index              2\n",
       "transit_index          302\n",
       "health_index          2031\n",
       "housing_index           73\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This joins all indexes together\n",
    "join1=restaurant_index_df.merge(crime_index_df,on=\"census_tract_geoid\",how='outer')\n",
    "join2=join1.merge(transit_index_df,on='census_tract_geoid',how='outer')\n",
    "join3=join2.merge(health_index_df,on='census_tract_geoid',how='outer')\n",
    "join4=join3.merge(housing_index_df,on='census_tract_geoid',how='outer')\n",
    "\n",
    "join4.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "census_tract_geoid       0\n",
       "restaurant_index       190\n",
       "crime_index              0\n",
       "transit_index          142\n",
       "health_index          1852\n",
       "housing_index           20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This removes rows with >3 missing indexes \n",
    "row_keep=[]\n",
    "for i in range(len(join4)):\n",
    "    if join4.iloc[i].isna().sum()<3:\n",
    "        row_keep.append(i)\n",
    "rows_underThree_na=join4.iloc[row_keep]\n",
    "rows_underThree_na.isnull().sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       census_tract_geoid  restaurant_index  crime_index  transit_index  \\\n",
      "count        2.147000e+03       2147.000000  2147.000000    2147.000000   \n",
      "mean         3.605447e+10          0.513076     0.082289       0.079448   \n",
      "std          2.602874e+07          0.070383     0.074766       0.088721   \n",
      "min          3.600500e+10          0.000000     0.001273       0.000000   \n",
      "25%          3.604702e+10          0.484677     0.033744       0.024336   \n",
      "50%          3.604712e+10          0.513406     0.059635       0.053097   \n",
      "75%          3.608103e+10          0.540808     0.106537       0.101770   \n",
      "max          3.608503e+10          1.000000     1.000000       1.000000   \n",
      "\n",
      "       health_index  housing_index  \n",
      "count   2147.000000    2147.000000  \n",
      "mean       0.057052       0.153622  \n",
      "std        0.041350       0.149094  \n",
      "min        0.000000       0.000000  \n",
      "25%        0.054743       0.045284  \n",
      "50%        0.055847       0.105861  \n",
      "75%        0.057743       0.214713  \n",
      "max        1.000000       1.000000  \n",
      "census_tract_geoid    3.605440e+10\n",
      "restaurant_index      5.150691e-01\n",
      "dtype: float64\n",
      "census_tract_geoid    3.605440e+10\n",
      "health_index          5.961024e-02\n",
      "dtype: float64\n",
      "census_tract_geoid    3.605518e+10\n",
      "crime_index           7.785858e-02\n",
      "dtype: float64\n",
      "census_tract_geoid    3.605402e+10\n",
      "transit_index         8.075112e-02\n",
      "dtype: float64\n",
      "census_tract_geoid    3.605492e+10\n",
      "housing_index         1.479722e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#This imputes missing data for missing indexes and outputs to csv\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "final_noNa=rows_underThree_na.copy()\n",
    "missing_data=['restaurant_index','health_index','transit_index','crime_index','housing_index']\n",
    "final_noNa[missing_data] = imp.fit_transform(final_noNa[missing_data])\n",
    "final_index=final_noNa.copy()\n",
    "final_index.loc[final_index[\"restaurant_index\"] < 0, \"restaurant_index\"] = 0\n",
    "final_index.loc[final_index[\"health_index\"] < 0, \"health_index\"] = 0\n",
    "final_index.loc[final_index[\"transit_index\"] < 0, \"transit_index\"] = 0\n",
    "final_index.loc[final_index[\"crime_index\"] < 0, \"crime_index\"] = 0\n",
    "final_index.loc[final_index[\"housing_index\"] < 0, \"housing_index\"] = 0\n",
    "final_index.to_csv(test_files+'Final/final_index.csv',index=False)\n",
    "print(final_index.describe())\n",
    "print(restaurant_index_df.mean())\n",
    "print(health_index_df.mean())\n",
    "print(crime_index_df.mean())\n",
    "print(transit_index_df.mean())\n",
    "print(housing_index_df.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULL evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jared\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:800: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "null_evaluation_run=True\n",
    "\n",
    "if null_evaluation_run==True:  \n",
    "\n",
    "    #Runs 10 times \n",
    "    mse_loop_list=[]\n",
    "    mse_loop=0\n",
    "    while mse_loop<10:\n",
    "        restaurant_null_perc=190/2147\n",
    "        transit_null_perc=142/2147\n",
    "        health_null_perc=1852/2147\n",
    "        housing_null_perc=20/2147\n",
    "        # Inital split on full index for __ %\n",
    "        final_index_missing=final_index.sample(frac = 1).reset_index()\n",
    "\n",
    "        # Add missing values to restaurant\n",
    "        restaurant_missing_eval=final_index_missing.sample(frac = restaurant_null_perc)\n",
    "        missing_restaurant=[]\n",
    "        for i in restaurant_missing_eval.index:\n",
    "            missing_restaurant.append(i)\n",
    "        for k in final_index_missing.index:\n",
    "            if k in missing_restaurant:\n",
    "                final_index_missing.loc[k,'restaurant_index_missing']=np.NaN\n",
    "            else: \n",
    "                final_index_missing.loc[k,'restaurant_index_missing']=final_index_missing.loc[k,'restaurant_index']\n",
    "\n",
    "        # Add missing values to transit\n",
    "        transit_missing_eval=final_index_missing.sample(frac = transit_null_perc)\n",
    "        missing_transit=[]\n",
    "        for i in transit_missing_eval.index:\n",
    "            missing_transit.append(i)\n",
    "        for k in final_index_missing.index:\n",
    "            if k in missing_transit:\n",
    "                final_index_missing.loc[k,'transit_index_missing']=np.NaN\n",
    "            else: \n",
    "                final_index_missing.loc[k,'transit_index_missing']=final_index_missing.loc[k,'transit_index']\n",
    "\n",
    "\n",
    "        # Add missing values to health\n",
    "        health_missing_eval=final_index_missing.sample(frac = health_null_perc)\n",
    "        missing_health=[]\n",
    "        for i in health_missing_eval.index:\n",
    "            missing_health.append(i)\n",
    "        for k in final_index_missing.index:\n",
    "            if k in missing_health:\n",
    "                final_index_missing.loc[k,'health_index_missing']=np.NaN\n",
    "            else: \n",
    "                final_index_missing.loc[k,'health_index_missing']=final_index_missing.loc[k,'health_index']\n",
    "\n",
    "\n",
    "        # Add missing values to housing\n",
    "        housing_missing_eval=final_index_missing.sample(frac = housing_null_perc)\n",
    "        missing_housing=[]\n",
    "        for i in housing_missing_eval.index:\n",
    "            missing_housing.append(i)\n",
    "        for k in final_index_missing.index:\n",
    "            if k in missing_housing:\n",
    "                final_index_missing.loc[k,'housing_index_missing']=np.NaN\n",
    "            else: \n",
    "                final_index_missing.loc[k,'housing_index_missing']=final_index_missing.loc[k,'housing_index']\n",
    "        \n",
    "        # GRAB ONLY NULL ROWS\n",
    "        null_rows = final_index_missing[final_index_missing.isnull().any(axis=1)]\n",
    "        max_rows=len(null_rows)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Using IterativeImputer fill in missing data that was just randomly generated\n",
    "        imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "        missing_data_eval=['restaurant_index_missing','health_index_missing','transit_index_missing','housing_index_missing']\n",
    "        final_index_missing[missing_data_eval] = imp.fit_transform(final_index_missing[missing_data_eval])\n",
    "\n",
    "        # CALC MSE \n",
    "        final_index_missing['restaurant_mse']=(final_index_missing['restaurant_index_missing']-final_index_missing['restaurant_index'])**2\n",
    "        final_index_missing['transit_mse']=(final_index_missing['transit_index_missing']-final_index_missing['transit_index'])**2\n",
    "        final_index_missing['health_mse']=(final_index_missing['health_index_missing']-final_index_missing['health_index'])**2\n",
    "        final_index_missing['housing_mse']=(final_index_missing['housing_index_missing']-final_index_missing['housing_index'])**2\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        mse=(sum(final_index_missing['restaurant_mse'])+sum(final_index_missing['transit_mse'])+sum(final_index_missing['health_mse'])+sum(final_index_missing['housing_mse']))/max_rows\n",
    "        mse_loop_list.append(mse)\n",
    "        mse_loop+=1\n",
    "    mse_average=np.average(mse_loop_list)\n",
    "    print(\"MSE: \"+str(mse_average))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
